{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **🧠 Definition of Neural Network (NN)**\n\nA **Neural Network** is a set of connected nodes (like mini brain cells) that work together to understand data and make predictions.\n\nIt’s a tool that helps computers learn from experience, similar \nto how humans learn.\n\n**🌟 Example:**\n\nIt can learn to recognize handwriting, voices, or even emotions in text by practicing on examples.\n\n\n## 📚 Simple Explanation\n\nThink of a neural network like a **brain made up of layers of \"neurons\"**.  \nThese neurons are just **math functions** that take some input (like images, text, or numbers), process it, and pass it to the next layer.\n\n- Each layer **learns something** about the data.\n- The network keeps **adjusting itself (training)** to make better predictions.\n- Finally, it gives you a **result/output** like:\n  - `\"This is a cat\"`\n  - `\"This sentence is positive\"`\n  - `\"This person has diabetes\"`\n\n---\n\n## 🧩 Neural Network Structure\n\n| **Layer Type**   | **What it Does**   | **Easy Example**                  |\n|------------------|--------------------|------------------------------------|\n| Input Layer      | Takes in data      | A picture of a cat                |\n| Hidden Layer(s)  | Learns patterns    | Finds cat features like ears, eyes |\n| Output Layer     | Gives the result   | Says “It’s a cat”                 |\n\n---\n\n## 🎯 Key Points\n\n- Neural networks **learn from data**, just like how we learn from experience.\n- They are used in **image recognition**, **language translation**, **voice assistants**, and more.\n- The more data you give, the **smarter** the network becomes.\n","metadata":{}},{"cell_type":"markdown","source":"# **🧠 Types of Neural Networks (NNs)**\n\n## **🔹 1. Feedforward Neural Network (FNN)**\n\n### 📘 Definition:\nThe most **basic neural network**. Data flows in **one direction** — from **input → hidden layer(s) → output**.\n\n### 🔧 Use Case:\n- Digit recognition (like 0–9)\n- Simple classification tasks\n\n🧠 Think: Like a straight road — no loops, no turning back\n\n### 🧠 Easy Explanation:\n- Like water flowing through a pipe — it **doesn’t loop back**. \n- 🧠 Think: Like a straight road — no loops, no turning back\n\n### 📊 Diagram:\n```text\nInput Layer      Hidden Layer     Output Layer\n   [X1]  ──▶       [O]  ──▶         [✓]\n   [X2]  ──▶       [O]  ──▶         [✗]\n   [X3]  ──▶       [O]  ──▶         [✓]\n```\n---\n","metadata":{}},{"cell_type":"markdown","source":"# **🔹2 Multilayer Perceptron (MLP)**\n\n### 📘 Definition:\nA **Multilayer Perceptron (MLP)** is a type of **Feedforward Neural Network** that has **multiple layers** of neurons:\n- One **Input Layer**\n- One or more **Hidden Layers**\n- One **Output Layer**\n\nEach layer is fully connected to the next layer. MLPs are trained using **backpropagation** and are widely used in deep learning tasks.\n\n### 🔧 Use Case:\n- Handwritten digit recognition (like MNIST)\n- Binary and multi-class classification\n- Stock price prediction\n- Spam detection\n\n### 🧠 Easy Explanation:\nThink of it like an onion with layers. Data passes from one layer to another, and each layer **learns something new** about the input.\n\n### 📊 Diagram:\n```text\nInput Layer         Hidden Layers             Output Layer\n   [X1] ──▶           [H1]                      [O1]\n   [X2] ──▶           [H2]                      [O2]\n   [X3] ──▶           [H3]                       \n                      [H4]                       \n                      [H5]                       \n```\n---","metadata":{}},{"cell_type":"markdown","source":"## **🔹 2. Convolutional Neural Network (CNN)**\n\n### 📘 Definition:\nSpecialized for **image processing**. It detects patterns like **edges, shapes, and textures** in pictures.\n\n### 🔧 Use Case:\n- Image classification (e.g., Cat vs Dog)  \n- Medical imaging  \n- Face detection\n\n### 🧠 Easy Explanation:\nLike your eyes scanning an image **part by part**, identifying shapes.\n\n### 📊 Diagram:\n```text\n[Input Image]\n     │\n[Convolution Layer]   → Extract features\n     │\n  [Pooling Layer]     → Downsample\n     │\n[Fully Connected Layer]\n     │\n   [Output]\n```\n---","metadata":{}},{"cell_type":"markdown","source":"# **🔹 3. Recurrent Neural Network (RNN)**\n\n### 📘 Definition:\nDesigned for **sequence data**. It has a memory of **previous inputs** to understand the current input better.\n\n### 🔧 Use Case:\n- Language modeling  \n- Text generation  \n- Time-series forecasting\n\n### 🧠 Easy Explanation:\nLike reading a sentence — each word depends on the **previous ones**.\n\n### 📊 Diagram:\n```text\nInput1 ──▶ 🧠 ──▶ Output1\n            │\nInput2 ──▶ 🧠 ──▶ Output2\n            │\nInput3 ──▶ 🧠 ──▶ Output3\n\n(🧠 = memory passed along the sequence)\n```\n---","metadata":{}},{"cell_type":"markdown","source":"# **🔹 4. Long Short-Term Memory (LSTM)**\n\n### 📘 Definition:\nAn advanced **RNN** that can **remember important information** for a longer time and **forget irrelevant info**.\n\n### 🔧 Use Case:\n- Chatbots  \n- Video analysis  \n- Stock prediction\n\n### 🧠 Easy Explanation:\nLike having a **notebook** — you remember useful things and skip the rest.\n\n### 📊 Diagram:\n```text\nInput1 ──▶ [LSTM Cell] ──▶ Output1\n               ↓\nInput2 ──▶ [LSTM Cell] ──▶ Output2\n               ↓\nInput3 ──▶ [LSTM Cell] ──▶ Output3\n```\n---","metadata":{}},{"cell_type":"markdown","source":"# **🔹 5. Generative Adversarial Network (GAN)**\n\n### 📘 Definition:\nA system of **two networks**:\n- **Generator:** Creates fake data  \n- **Discriminator:** Detects whether it’s real or fake\n\n### 🔧 Use Case:\n- Deepfake generation  \n- Image-to-image translation  \n- AI-generated art\n\n### 🧠 Easy Explanation:\nLike a **forger and a detective** — both improve by trying to beat each other.\n\n### 📊 Diagram:\n```text\n[Random Noise]\n      │\n  🎨 Generator ─────▶ Fake Image ─────▶ 🤖 Discriminator\n                                        │\n                                  Real or Fake?\n```\n---","metadata":{}},{"cell_type":"markdown","source":"# **🔹 6. Radial Basis Function Network (RBF)**\n\n### 📘 Definition:\nUses the **distance** between input data and predefined center points to make decisions.\n\n### 🔧 Use Case:\n- Pattern recognition  \n- Classification tasks  \n- Function approximation\n\n### 🧠 Easy Explanation:\nLike **grouping people** by how close they are to known examples.\n\n### 📊 Diagram:\n```text\n[Input] ──▶ [RBF Layer] ──▶ [Output]\n              │\n     (Check distance to known points)\n```\n---","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}