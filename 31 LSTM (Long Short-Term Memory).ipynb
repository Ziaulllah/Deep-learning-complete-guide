{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🧠 LSTM (Long Short-Term Memory ) – Complete Guide\n",
    "\n",
    "---\n",
    "\n",
    "## 📜 What is LSTM?\n",
    "\n",
    "**LSTM (Long Short-Term Memory)** is a special kind of **Recurrent Neural Network (RNN)** that is able to **remember information for a long time** and forget unnecessary details.\n",
    "\n",
    "> 🔥 It solves the *vanishing gradient problem* faced by regular RNNs.\n",
    "\n",
    "---\n",
    "\n",
    "## 🕰️ History of LSTM\n",
    "\n",
    "| Year | Milestone |\n",
    "|------|-----------|\n",
    "| **1991** | RNNs (Elman, Jordan) introduced |\n",
    "| **1997** | LSTM invented by **Hochreiter & Schmidhuber** |\n",
    "| **2015+** | Used in **Google Translate, Siri, etc.** |\n",
    "| **Today** | Core part of **NLP, speech, and time series systems** |\n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 Why Use LSTM?\n",
    "\n",
    "### 🧠 RNN Limitations:\n",
    "- Struggles with **long sequences**\n",
    "- **Forgets past info**\n",
    "- Faces **vanishing gradient problem**\n",
    "\n",
    "### ✅ LSTM Advantages:\n",
    "- **Remembers long-term dependencies**\n",
    "- Uses **gates to control memory**\n",
    "- Avoids vanishing gradient issue\n",
    "\n",
    "---\n",
    "\n",
    "## 🔁 High-Level Working\n",
    "\n",
    "Imagine LSTM as a smart memory box with:\n",
    "\n",
    "1. 🔐 **Input Gate** – What to store?\n",
    "2. 🧹 **Forget Gate** – What to forget?\n",
    "3. 📤 **Output Gate** – What to output?\n",
    "4. 🧠 **Cell State** – Memory over time\n",
    "\n",
    "---\n",
    "\n",
    "## 🧱 Architecture – Step by Step\n",
    "\n",
    "```plaintext\n",
    "        ┌──────────────┐\n",
    "        │  Previous h  │\n",
    "        └─────┬────────┘\n",
    "              │\n",
    "        ┌─────▼────────┐\n",
    "        │  Forget Gate │ ← Decides what to forget\n",
    "        └─────┬────────┘\n",
    "              │\n",
    "        ┌─────▼────────┐\n",
    "        │ Input Gate   │ ← What new info to add\n",
    "        └─────┬────────┘\n",
    "              │\n",
    "        ┌─────▼────────┐\n",
    "        │  Cell State  │ ← Updates memory (long term)\n",
    "        └─────┬────────┘\n",
    "              │\n",
    "        ┌─────▼────────┐\n",
    "        │ Output Gate  │ ← What to output this step\n",
    "        └─────┬────────┘\n",
    "              │\n",
    "        ┌─────▼────────┐\n",
    "        │  New h(t)    │\n",
    "        └──────────────┘\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "## 🧩 Components Explained\n",
    "\n",
    "### 🧠 1. Cell State (Cₜ) – Long-term memory\n",
    "Like a conveyor belt carrying information\n",
    "\n",
    "Adjusted by forget & input gates\n",
    "\n",
    "---\n",
    "\n",
    "### 🔁 2. Hidden State (hₜ) – Short-term memory\n",
    "Represents output at time t\n",
    "\n",
    "Passed to the next step\n",
    "\n",
    "---\n",
    "\n",
    "## 🧪 Gates and Their Roles (with Equations)\n",
    "\n",
    "### 🔐 Forget Gate – What to forget?\n",
    "\n",
    "𝑓ₜ = 𝜎(𝑊𝑓 ⋅ [ℎₜ₋₁, 𝑥ₜ] + 𝑏𝑓)\n",
    "\n",
    "fₜ = σ(Wf ⋅ [ht−1, xt] + bf)\n",
    "\n",
    "Output between 0 (forget) and 1 (keep)\n",
    "\n",
    "---\n",
    "\n",
    "### ✍️ Input Gate – What to add?\n",
    "\n",
    "𝑖ₜ = 𝜎(𝑊𝑖 ⋅ [ℎₜ₋₁, 𝑥ₜ] + 𝑏𝑖)\n",
    "\n",
    "𝐶̃ₜ = tanh(𝑊𝐶 ⋅ [ℎₜ₋₁, 𝑥ₜ] + 𝑏𝐶)\n",
    "\n",
    "it = σ(Wi ⋅ [ht−1, xt] + bi)  \n",
    "Ĉₜ = tanh(WC ⋅ [ht−1, xt] + bC)\n",
    "\n",
    "Determines what new memory to add\n",
    "\n",
    "---\n",
    "\n",
    "### 🔁 Update Cell State\n",
    "\n",
    "𝐶ₜ = 𝑓ₜ ⋅ 𝐶ₜ₋₁ + 𝑖ₜ ⋅ 𝐶̃ₜ\n",
    "\n",
    "Ct = ft ⋅ Ct−1 + it ⋅ Ĉₜ\n",
    "\n",
    "Combines old memory + new info\n",
    "\n",
    "---\n",
    "\n",
    "### 📤 Output Gate – What to output?\n",
    "\n",
    "𝑜ₜ = 𝜎(𝑊𝑜 ⋅ [ℎₜ₋₁, 𝑥ₜ] + 𝑏𝑜)\n",
    "\n",
    "ℎₜ = 𝑜ₜ ⋅ tanh(𝐶ₜ)\n",
    "\n",
    "ot = σ(Wo ⋅ [ht−1, xt] + bo)  \n",
    "ht = ot ⋅ tanh(Ct)\n",
    "\n",
    "Produces hidden/output state\n",
    "\n",
    "---\n",
    "\n",
    "## 🔄 Full Flow of LSTM at Time Step t\n",
    "\n",
    "- Take input xₜ and previous output hₜ₋₁\n",
    "- Use Forget Gate → forget some old memory\n",
    "- Use Input Gate → decide new memory\n",
    "- Update Cell State Cₜ\n",
    "- Use Output Gate → get output hₜ\n",
    "\n",
    "---\n",
    "\n",
    "## 📦 Real-World Use Cases\n",
    "\n",
    "| Task                | LSTM Use                    |\n",
    "|---------------------|-----------------------------|\n",
    "| Text Generation     | Predict next words          |\n",
    "| Chatbots            | Keep conversation context   |\n",
    "| Time Series         | Predict future values       |\n",
    "| Speech Recognition  | Understand entire sentence  |\n",
    "| Machine Translation | Maintain meaning through sentence |\n",
    "\n",
    "---\n",
    "\n",
    "## 🆚 RNN vs LSTM vs GRU\n",
    "\n",
    "| Feature     | RNN  | LSTM                       | GRU               |\n",
    "|-------------|------|----------------------------|-------------------|\n",
    "| Memory      | Short| Long                       | Long              |\n",
    "| Gates       | 0    | 3 (forget, input, output)  | 2 (update, reset) |\n",
    "| Performance | Poor for long sequences | Great         | Faster            |\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 Final Summary (in Simple Words)\n",
    "\n",
    "- LSTM is a special RNN designed to remember useful data and forget noise\n",
    "- Uses three gates to control memory\n",
    "- Solves RNN’s vanishing gradient problem\n",
    "- Great for sequence-based tasks like language, sound, and time series\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
