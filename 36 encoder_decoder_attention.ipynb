{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e888bc8",
   "metadata": {},
   "source": [
    "# 🔄 Encoder–Decoder + Attention (Step by Step)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. 🌍 Why Encoder–Decoder?\n",
    "\n",
    "**Definition:**  \n",
    "An Encoder–Decoder model is a neural network structure used for tasks like translation, summarization, and text generation. It has two parts:\n",
    "\n",
    "- Encoder reads and converts the input into hidden states.  \n",
    "- Decoder generates the output step by step.  \n",
    "\n",
    "📌 Example: Translate English → Urdu  \n",
    "\n",
    "- Input: “How are you?”  \n",
    "- Output: “آپ کیسے ہیں؟”  \n",
    "\n",
    "We need a system that:  \n",
    "- Reads the input sentence.  \n",
    "- Understands it.  \n",
    "- Generates the output sentence.  \n",
    "\n",
    "---\n",
    "\n",
    "## 2. 🧩 Encoder–Decoder Architecture\n",
    "\n",
    "Think of it like two friends passing information:\n",
    "\n",
    "- Encoder = Like a reader. It reads the input word by word and converts it into a summary (hidden representation).  \n",
    "- Decoder = Like a speaker. It takes that summary and produces the output sentence word by word.  \n",
    "\n",
    "📌 Problem: For long sentences, the encoder’s summary may forget important details.  \n",
    "👉 Attention solves this.  \n",
    "\n",
    "---\n",
    "\n",
    "## 3. 👀 Attention Mechanism\n",
    "\n",
    "**Definition:**  \n",
    "The Attention mechanism allows the model to focus on the most relevant parts of the input sentence when generating each output word.  \n",
    "\n",
    "⚡ Example:  \n",
    "- While generating “ہیں”, the model looks mainly at “are”.  \n",
    "- While generating “آپ”, the model looks at “you”.  \n",
    "\n",
    "👉 In short: Attention = focus on the right word at the right time.  \n",
    "\n",
    "---\n",
    "\n",
    "## 4. 🎯 Bahdanau Attention (Additive Attention)\n",
    "\n",
    "**Definition:**  \n",
    "Bahdanau Attention (2014) is an additive attention mechanism that uses a small neural network to decide how much focus (weight) should be given to each input word when generating the next output word.  \n",
    "\n",
    "**Steps:**  \n",
    "1. Take the decoder’s current state (s_t).  \n",
    "2. Compare it with all encoder hidden states (h1, h2, h3 …).  \n",
    "3. A small NN calculates a score for each encoder hidden state.  \n",
    "4. Apply softmax → scores become attention weights.  \n",
    "5. Take a weighted sum of encoder states → this becomes the context vector.  \n",
    "6. Decoder uses this context vector to generate the next word.  \n",
    "\n",
    "👉 In short: Bahdanau Attention = dynamic spotlight that shifts focus to different input words as output is generated.  \n",
    "\n",
    "---\n",
    "\n",
    "## 5. 🎯 Luong Attention (Multiplicative Attention)\n",
    "\n",
    "**Definition:**  \n",
    "Luong Attention (2015) is a multiplicative attention mechanism that calculates the importance of input words using a simple dot product (instead of a small NN).  \n",
    "\n",
    "**Types of Luong Attention:**  \n",
    "- Dot → Score = dot product of encoder state & decoder state.  \n",
    "- General → Score = decoder state × weight matrix × encoder state.  \n",
    "- Concat → Similar to Bahdanau, but less common in Luong’s version.  \n",
    "\n",
    "**Steps:**  \n",
    "1. Take the decoder state and encoder states.  \n",
    "2. Use dot product (or weighted dot) to get scores.  \n",
    "3. Apply softmax → attention weights.  \n",
    "4. Weighted sum → context vector.  \n",
    "5. Decoder uses this vector to predict the next word.  \n",
    "\n",
    "👉 In short: Luong Attention = faster than Bahdanau because it uses dot product instead of a neural network.  \n",
    "\n",
    "---\n",
    "\n",
    "## 6. 📊 Workflow Diagram (Simple)\n",
    "\n",
    "```plaintext\n",
    "Input Sentence → [ Encoder ] → Hidden states → Attention → [ Decoder ] → Output Sentence\n",
    "\n",
    "- Encoder → gives hidden states for each word.\n",
    "- Attention → decides which hidden states matter at each step.\n",
    "- Decoder → uses them to generate the next word.\n",
    "\n",
    "```\n",
    "\n",
    "## ✅ Easy Summary\n",
    "\n",
    "- **Encoder** = Reads input sentence.\n",
    "- **Decoder** = Generates output sentence.\n",
    "- **Attention** = Helps decoder “look at the right word at the right time.”\n",
    "- **Bahdanau Attention (Additive)** = Uses a small neural network to calculate attention scores.\n",
    "- **Luong Attention (Multiplicative)** = Uses dot product (faster, simpler)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bf8110",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
