{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20997de4",
   "metadata": {},
   "source": [
    "# ğŸ” Bidirectional RNN â€“ Explained in Simple Terms\n",
    "\n",
    "## ğŸ§  What is a Bidirectional RNN?\n",
    "\n",
    "A **Bidirectional RNN (Bi-RNN)** is a type of Recurrent Neural Network that reads input sequences in **both directions**:\n",
    "\n",
    "- **Forward pass**: from start to end\n",
    "- **Backward pass**: from end to start\n",
    "\n",
    "It then **combines the results** to make better predictions.\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Why Use Bidirectional RNN?\n",
    "\n",
    "In some tasks, knowing **both past and future** is important.  \n",
    "For example:\n",
    "\n",
    "> â€œHe went to the ______.â€  \n",
    "If we also read backward and see â€œ______ hospital.â€  \n",
    "Then we clearly understand the missing word is \"hospital\".\n",
    "\n",
    "**Bi-RNN = Forward Understanding + Backward Understanding**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§± Architecture Overview\n",
    "```\n",
    "Input Sequence:    x1  â†’  x2  â†’  x3  â†’  x4\n",
    "\n",
    "Forward RNN:       â†’â†’â†’â†’â†’â†’â†’â†’â†’â†’â†’â†’â†’â†’â†’â†’â†’â†’\n",
    "Backward RNN:       â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†\n",
    "\n",
    "Output:          [h1_f + h1_b], [h2_f + h2_b], ...\n",
    "```\n",
    "\n",
    "- `h_f`: Hidden state from forward RNN\n",
    "- `h_b`: Hidden state from backward RNN\n",
    "- Final output: combination (usually concatenation) of both\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“¦ Types of Bidirectional RNN Layers\n",
    "\n",
    "You can use **Bidirectional** with any RNN-type layer:\n",
    "\n",
    "- `Bidirectional(SimpleRNN(...))`\n",
    "- `Bidirectional(LSTM(...))`\n",
    "- `Bidirectional(GRU(...))`\n",
    "\n",
    "---\n",
    "\n",
    "## **âœ… Keras Code Example â€“ Bidirectional SimpleRNN**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9999a600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load IMDB dataset\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "\n",
    "# Pad sequences to equal length\n",
    "x_train = pad_sequences(x_train, maxlen=100)\n",
    "x_test = pad_sequences(x_test, maxlen=100)\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    Embedding(10000, 32, input_length=100),\n",
    "    Bidirectional(SimpleRNN(32)),  # Bidirectional wrapper\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile and train\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9ef3c7",
   "metadata": {},
   "source": [
    "## ğŸ“Š Output Shape Notes\n",
    "\n",
    "- `SimpleRNN(32)` â†’ **32 outputs**\n",
    "- `Bidirectional(SimpleRNN(32))` â†’ **64 outputs**  \n",
    "  (32 from forward + 32 from backward)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Œ When to Use Bidirectional RNN?\n",
    "\n",
    "âœ… Use **Bidirectional RNN** when:\n",
    "\n",
    "- **Future context** helps understand the current input\n",
    "- For tasks like:\n",
    "  - **Sentiment analysis**\n",
    "  - **Named Entity Recognition (NER)**\n",
    "  - **Speech recognition**\n",
    "  - **Sequence tagging**\n",
    "  - **Machine translation**\n",
    "\n",
    "âš ï¸ **Keep in mind:**\n",
    "\n",
    "- It is **slower and heavier** than normal RNN\n",
    "- Requires **more memory** and **longer training time**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ Bonus: Bidirectional LSTM / GRU\n",
    "\n",
    "You can easily replace `SimpleRNN` with `LSTM` or `GRU` like this:\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.layers import LSTM, GRU, Bidirectional\n",
    "\n",
    "# Bidirectional LSTM\n",
    "Bidirectional(LSTM(64))\n",
    "\n",
    "# Bidirectional GRU\n",
    "Bidirectional(GRU(64))\n",
    "```\n",
    "### **ğŸ§¡ Tip:**\n",
    "Bidirectional layers often boost performance and accuracy in NLP tasks!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
