{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# üß† Understanding Optimizers in Deep Learning\n\n## Step 1: What is an Optimizer?\nAn **Optimizer** is an algorithm that updates the weights of your neural network to minimize the loss function. It's the engine that drives the learning process in your model.\n\n## Step 2: Why Do We Need Optimizers?\nWhen training a model, we aim to:\n- Make accurate predictions\n- Reduce the loss (error) between predicted and actual values\n\n**Solution**: Optimizers adjust weights and biases using gradient descent methods.\n\n## Step 3: How Optimizers Work\nThe training loop consists of:\n1. **Forward pass**: Predict the output\n2. **Compute loss**: Compare prediction vs actual\n3. **Backward pass**: Calculate gradients (backpropagation)\n4. **Update weights**: Optimizer adjusts weights to reduce loss\n\nThis loop repeats for multiple epochs (full dataset passes).\n\n## Step 4: Types of Optimizers\n\n### 1. Gradient Descent (GD)\n- Updates weights using entire training data\n- ‚úÖ High accuracy\n- ‚ùå Slow and memory-intensive\n- Rarely used in practice\n\n### 2. Stochastic Gradient Descent (SGD)\n```python\nfrom tensorflow.keras.optimizers import SGD\nopt = SGD(learning_rate=0.01)\n```\n**Updates using single samples**\n\n- ‚úÖ Fast\n- ‚ùå Noisy updates\n- May oscillate near optimum\n\n### 3. Mini-Batch Gradient Descent\n- Combines GD and SGD advantages\n- Updates using small batches (32-512 samples)\n- Most widely used in practice\n\n","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}